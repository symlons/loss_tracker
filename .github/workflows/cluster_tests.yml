name: Cluster Testing

on:
  push:
    branches: [redo]
  pull_request:
    branches: [redo]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Set up Kind cluster
        uses: engineerd/setup-kind@v0.5.0
        with:
          version: v0.17.0

      - name: Clean up existing Kind cluster (if any)
        run: |
          kind get clusters && kind delete cluster --name kind || echo "No existing Kind cluster found"

      - name: Create Kind cluster
        run: |
          kind create cluster
          sleep 5  # Adding a delay to ensure cluster is fully initialized

      - name: Set up kubectl for Kind cluster
        run: |
          export KUBEVERSION=$(kind version --client)
          echo "Kube version: $KUBEVERSION"
          kind get kubeconfig > kubeconfig.yaml
          export KUBECONFIG=kubeconfig.yaml
          kubectl cluster-info  # Verify the cluster is up and running

      - name: Validate YAML manifests with kubeval (skip unknown schemas)
        run: |
          # Download and extract kubeval
          curl -LO https://github.com/instrumenta/kubeval/releases/latest/download/kubeval-linux-amd64.tar.gz
          tar xf kubeval-linux-amd64.tar.gz
          chmod +x kubeval
          # Use kubeval with --ignore-missing-schemas flag to skip missing schema errors
          ./kubeval production/full2.yaml production/secret.yaml --ignore-missing-schemas

      - name: Retry Apply Kubernetes Manifests
        run: |
          kubectl create namespace losstracker
          kubectl apply -f production/full2.yaml --validate=false && break || sleep 15
          kubectl apply -f production/secret.yaml --validate=false
          kubectl apply -f production/traefik-roles.yaml --validate=false

      - name: Wait for deployments to become ready
        run: |
          kubectl rollout status deployment/traefik -n losstracker --timeout=220s
          kubectl rollout status deployment/loss-tracker-nginx-client -n losstracker --timeout=220s

      - name: Test Client Ingress connectivity
        run: |
          echo "Port-forwarding client service to localhost:8080"
          kubectl port-forward svc/loss-tracker-nginx-client 8080:80 -n losstracker &
          PF_PID=$!
          # Give port-forward time to initialize
          sleep 10
          echo "Checking client service response..."
          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8080/)
          echo "HTTP status code: $HTTP_CODE"
          if [ "$HTTP_CODE" != "200" ]; then
            echo "Client connectivity test failed"
            kill $PF_PID
            exit 1
          fi
          kill $PF_PID
          echo "Client connectivity test passed"

      - name: Test API Ingress connectivity (if available)
        run: |
          echo "Checking for load-balancer-server service..."
          SERVICE_EXISTS=$(kubectl get svc load-balancer-server -n losstracker --ignore-not-found)
          if [ -n "$SERVICE_EXISTS" ]; then
            echo "Service found, waiting for pod to be in Running state..."
            kubectl wait --for=condition=ready pod -l app=loss-tracker-server -n losstracker --timeout=120s
            echo "Service found, port-forwarding API service to localhost:5005"
            kubectl port-forward svc/load-balancer-server 5005:5005 -n losstracker &
            PF_API_PID=$!
            sleep 10
            echo "Checking API endpoint response..."
            HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:5005/)
            echo "HTTP status code: $HTTP_CODE"
            if [ "$HTTP_CODE" != "200" ]; then
              echo "API connectivity test failed"
              kill $PF_API_PID
              exit 1
            fi
            kill $PF_API_PID
            echo "API connectivity test passed"
          else
            echo "Service load-balancer-server not found; skipping API connectivity test"
          fi

      - name: Test Traefik routing for /api path
        run: |
          echo "Testing Traefik routing for /api path"
          INGRESS_EXISTS=$(kubectl get ingress -n losstracker --ignore-not-found -o jsonpath='{.items[0].metadata.name}')
          echo "Ingress exists: $INGRESS_EXISTS"
          if [ -n "$INGRESS_EXISTS" ]; then
            echo "Ingress found: $INGRESS_EXISTS. Proceeding to check routing for /api"
            
            # Get the correct Traefik LoadBalancer or NodePort IP
            TRAEFIK_IP=$(kubectl get svc traefik -n losstracker -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
            
            # If LoadBalancer IP is not found, use the NodePort IP from Kind's internal API server
            if [ -z "$TRAEFIK_IP" ]; then
              TRAEFIK_IP=$(kubectl get svc traefik -n losstracker -o jsonpath='{.spec.clusterIP}')
            fi

            echo "Traefik IP: $TRAEFIK_IP"

            # Test the routing for /api
            HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" -H "Host: mlstatstracker.org" http://$TRAEFIK_IP/api)
            echo "HTTP status code received for /api: $HTTP_CODE"
            if [ "$HTTP_CODE" != "200" ]; then
              echo "ERROR: Traefik routing for /api path failed. Received HTTP code: $HTTP_CODE"
            fi
            echo "Traefik routing for /api path passed successfully with HTTP status 200"
          else
            echo "Ingress not found in namespace 'losstracker'; skipping /api path routing test"
          fi

